#!/usr/bin/env bash

################################################
# PROGRAM:
# `summitRNAseq_PE_analyzer.sh`
#
# DESCRIPTION:
# An RNA-seq pipeline for usage on the RMACC Summit Compute Cluster. The Singularity container 
# `summitRNAseq.simg` was built to work alongside this pipeline. This RNA-seq pipeline will analyze 
# paired-end (PE) FASTQ sequencing reads generated by the Illumina sequencing platform. This 
# pipeline will perform quality control, read trimming, genome alignment, basic format
# conversions, and featureCounts tabulation for paired-end RNA-seq samples using a specified
# genome. 
#
# AUTHOR:
# Robert Thomas Patton Williams, modified from Erin Osborne Nishimura
#
# START DATE:
# July 10, 2019
#
# CONTAINER:
# `summitRNAseq.simg`
#
#   See https://github.com/rtpwilliams/Summit_RNAseq_container for Singularity build recipe. To 
#   download this container type the following command:
#
#               $ singularity pull shub://rtpwilliams/Summit_RNAseq_container:master
#
#  This container provides the following software:
#  - fastp=0.20.0
#  - hisat2=2.1.0
#  - picard=2.18.27
#  - conda-forge::r-data.table=1.12.0
#  - conda-forge::r-gplots=3.0.1.1
#  - bioconductor-deseq2=1.22.1
#  - conda-forge::r-markdown=0.9
#  - samtools=1.9
#  - deeptools=3.2.0
#  - bedtools=2.28.0
#  - htseq=0.11.2
#  - subread=1.6.4
#
# 
#
# REQUIRES:
#    INPUT: .fastq files.    For each sample, paired forward and reverse sequencing files
#								are required. These should be placed in an input
#								directory.
#
#    INPUT: _metadata.txt file: A tab-separated metadata file with at least one columns. The first 
#								column is the fastq file name for read one (R1) without the `.fastq.gz` suffix. 
#               The second column is a fastq file name for read two (R2) without the `.fastq.gz` suffix
#               The third column contains a "nickname" of each sample that will be used for directory
#               naming. Additional columns can be included with other metadata information.
#								The Metadata file should be placed within the `inputdir` directory.
#
#
#    HISAT2 INDEXES: `.ht2` files for the genome. These are produced using `hisat2-build`. For
#								instructions see
#	           https://ccb.jhu.edu/software/hisat2/manual.shtml#the-hisat2-build-indexer
#
#    GENOME SEQUENCE: `.fa`  or `.tar.gz` file for the genome. This is the sequence of the 
#                                genome.
#
#    GENOME ANNOTATION: `.gtf` file for the genome. This is a genome annotation file of gene
#								features. Version and coordinates must match the genome
#								sequence (.fa above).
#
# USAGE:
# $ bash summitRNAseq_SE_analyzer.sh <metadata.txt> <number of threads>
#
# OUTPUT:
#
# KNOWN BUGS:
#
# THINGS TO IMPROVE:
# Add singularity hub link once the server is back up.
# Align reads to ERCC spike in file
# Explicitly give fastp the adapter sequences - Done, needs testing
################################################


echo -e ">>> INITIATING analyzer with command:\n \t $0 $@"


####### MODIFY THIS SECTION #############
# Edit this section to reflect to location of the relevant files

#The input samples (metadata file and _fastq.gz files) live in directory:
inputdir="/pl/active/onishimura_lab/PROJECTS/RR_ARPE_DELUCA_COLLAB/01_input/"

#This is where the ht2 files live:
hisat2path="/projects/dcking@colostate.edu/support_data/hg38/hg38"

#This is where the genome sequence lives:
genomefa="/projects/dcking@colostate.edu/support_data/hg38/hg38chromFa.fa"

#This is where the gtf file lives:
gtffile="/projects/dcking@colostate.edu/support_data/hg38/hg38_pc_20200113_UCSC_compatible.gtf"
    
#Number of threads to use:
pthread=$2

#This is where the singularity container lives:
container="/projects/rtpw@colostate.edu/container_images/summitRNAseq.simg"

#This is the suffix of the files submitted to the analyzer:
suffix=".fastq"

#This is the location of the FASTA file for trimming sequencing adapters
adapterfa="/projects/rtpw@colostate.edu/Adapter_Trimming_FASTAs/NEBNext_Ultra_II_Index_Primers.fasta"

#This is the location of the FASTA file for the ERCC spike in controls
erccfa="/projects/rtpw@colostate.edu/ce11_ERCC_merged/ERCC92.fa"

#This is the location of the GTF file for the ERCC spike in controls
erccgtf="/projects/rtpw@colostate.edu/ce11_ERCC_merged/ERCC92.gtf"

### CONTAINER ALIASES ###
module purge
module load singularity/3.3.0
fastp="singularity run $container fastp"
hisat2="singularity run $container hisat2"
samtools="singularity run $container samtools"
bamCoverage="singularity run $container bamCoverage"
featureCounts="singularity run $container featureCounts"

### STANDARD PROGRAM INSTALL###
# module purge
# PROJ_DIR=/projects/dcking@colostate.edu
# source $PROJ_DIR/paths.bashrc
# 
# fastp="fastp"
# hisat2="hisat2"
# samtools="samtools"
# featureCounts="featureCounts"
# bamCoverage="bamCoverage"


########## DONE MODIFYING ###############

#This is the output_directory:

DATE=`date +%Y-%m-%d`
#DATE='2018-10-16'
outputdir="../03_output/"$DATE"_RRoutput_robs/"


echo -e ">>> MAKING output directory"
echo -e "\t mkdir $outputdir"
mkdir -p $outputdir



####### META DATA #############



#These are the sample files for read 1 (R1):
sample1=( $(cut -f 1 --output-delimiter='\t' $1) )

echo $sample1

#These are the sample files for read 2 (R2):
sample2=( $(cut -f 2 --output-delimiter='\t' $1) )

echo $sample2

#These are the nicknames I want to give the files:
names=( $(cut -f 3 --output-delimiter='\t' $1) )
echo $names


 ####### PIPELINE ##############

# Report back to the user which files will be processed and which names they'll be given:
echo -e ">>> INPUT: This script will process files from the metafile:\n\t$1"
echo -e ">>> PLAN: This script will process the sample files into the following names: "
echo -e "\t SAMPLE_READ_1 \t SAMPLE_READ_2 \t NAMES"

for (( counter=0; counter < ${#sample1[@]}; counter++ ))
do
    echo -e "\t ${sample1[$counter]}\t ${sample2[$counter]}\t ${names[$counter]}"
done

 # FASTP to determine quality
 echo -e "\n >>> FASTP: analyzing quality of each .fastq file"


 for (( counter=0; counter < ${#sample1[@]}; counter++ ))
 do
   samplename=${names[$counter]}
   echo -e "\n Sample Name: $samplename"

   read1=${sample1[$counter]}
   echo -e "\n Read 1: $read1"

   read2=${sample2[$counter]}
  echo -e "\n Read 2: $read2"     

  #Make trimmed fastq output directories
  fastpTrim=$outputdir"02_fastp_trim/"$samplename/
  mkdir -p $fastpTrim
  echo -e "\n FASTP trimmed files are located in:\n $fastpTrim"

  #Make fastp report directories
  fastpReport=$outputdir"01_fastp_reports/"
  mkdir -p $fastpReport
  echo -e "\n FASTP quality reports are located in:\n $fastpReport"

    ## execute fastp
    cmd1="$fastp -i ${inputdir}${read1}${suffix} -I ${inputdir}${read2}${suffix} -o ${fastpTrim}${read1}_trim${suffix}.gz -O ${fastpTrim}${read2}_trim${suffix}.gz --json=${fastpReport}${read1}_report.json --html=${fastpReport}${read1}_report.html -g -x -p -w $pthread"
    # input is read 1 (-i) and read 2 (-I) of sample, output is trimmed read 1 and read 2 and quality report for the pair.
    # options: 
    # -g (trim poly g)
    # -x (trim poly X tail, ie. polyT or polyA)
    # -p (overrepresented sequence analysis)
    # --adapter_fasta (specify a fasta file containing a list of possible sequences to trim)
    echo -e "\t $ ${cmd1}"
    time eval $cmd1
done

# HISAT2 to align to the genome
echo -e "\n>>> HISAT2: aligning each sample to the genome"
 outhisat2=$outputdir"03_hisat2/"
mkdir -p $outhisat2
echo -e "Alignment output located in directory $outhisat2"


for (( counter=0; counter < ${#sample1[@]}; counter++ ))
do
  samplename=${names[$counter]}
  echo -e "\n Sample name: $samplename"
  read1=${sample1[$counter]}_trim
  echo "Read 1: $read1"
  read2=${sample2[$counter]}_trim
  echo "Read 2: $read2"
  fastpTrim=$outputdir"02_fastp_trim/"$samplename/
    ## execute hisat2
    cmd3="$hisat2 -x $hisat2path -1 ${fastpTrim}${read1}${suffix}.gz -2 ${fastpTrim}${read2}${suffix}.gz -S ${outhisat2}${read1}.sam --summary-file ${outhisat2}${read1}_summary.txt --un-conc ${outhisat2}${read1}_unaligned.sam -p $pthread"
    echo -e "\t$ $cmd3"
  time eval $cmd3

done

# FEATURECOUNTS to tabulate reads per gene:
echo -e "\n>>> FEATURECOUNTS: Run featureCounts on all files to tabulate read counts per gene"
outfeature=$outputdir"04_feature/"
mkdir -p $outfeature
echo -e "Tabulation output files are located in: $outfeature"

# Acquire a list of .sam names
samfilePath=()
echo "Acquire .sam file names"
for (( counter=0; counter < ${#names[@]}; counter++ ))
do
    samfile=${sample1[$counter]}_trim.sam
    echo "File: $samfile"
    samfilePath+=(${outhisat2}${samfile})
    echo "Path: ${samfilePath[$counter]}"

done

# Execute featureCounts
cmd4="$featureCounts -p -Q 20 -T ${pthread} -a $gtffile -o ${outfeature}counts.txt ${samfilePath[*]}"
echo -e "\n \t $ $cmd4"
time eval $cmd4

# SAMTOOLS and BAMCOVERAGE: to convert .sam output to uploadable .bam and .wg files
echo -e "\n>>> SAMTOOLS/BAMCOVERAGE: to convert files to uploadable _sort.bam and _sort.bam.bai files:"
samout=$outputdir"05_samtools/"
mkdir -p $samout
echo -e "\t Samtools output files located in: $samout"

for seqname in ${sample1[@]}
do
    echo -e "\n >>> Converting Filex: ${seqname}"
    
    # Samtools: compress .sam -> .bam
    cmd5="$samtools view --threads $pthread -bS ${outhisat2}${seqname}_trim.sam > ${samout}${seqname}_trim.bam"
  echo -e "\t $ ${cmd5}"
  time eval $cmd5
  cmd5a="$samtools quickcheck ${samout}${seqname}_trim.bam"
  echo -e "\t $ ${cmd5a}"
  time eval $cmd5a
  if [ $? -eq 0 ]
  then
    rm -v ${outhisat2}${seqname}_trim.sam
  fi
  
  
    
    # Samtools: sort .bam -> _sort.bam
    cmd6="$samtools sort --threads $pthread -o ${samout}${seqname}_trim_sort.bam --reference $genomefa ${samout}${seqname}_trim.bam"
    echo -e "\t$ ${cmd6}"
    time eval $cmd6
    
    
    # Samtools: index _sort.bam -> _sort.bam.bai
    cmd7="$samtools index ${samout}${seqname}_trim_sort.bam"
    echo -e "\t$ ${cmd7}"
    time eval $cmd7
    
    
    # bamCoverage: 
    cmd8="$bamCoverage -b ${samout}${seqname}_trim_sort.bam -o ${samout}${seqname}_trim_sort.bw --outFileFormat bigwig -p $pthread --normalizeUsing CPM --binSize 1"
    echo -e "\t$ ${cmd8}"
    time eval $cmd8
done


######## VERSIONS #############
echo -e "\n>>> VERSIONS:"
echo -e "\n>>> FASEQC VERSION:"
$fastqc --version
echo -e "\n>>> HISAT2 VERSION:"
$hisat2 --version
echo -e "\n>>> SAMTOOLS VERSION:"
$samtools --version
echo -e "\n>>> FEATURECOUNTS VERSION:"
$featureCounts -v
echo -e "\n>>> BAMCOVERAGE VERSION:"
$bamCoverage --version
echo -e ">>> END: Analayzer complete."
